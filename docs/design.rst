General design documentation
============================

The underlying design principle
-------------------------------

-  対話環境 (e.g., IPython, Jupyter) での試行錯誤は、生産性の向上に重要である

TODO: Think carefully
---------------------

- end-to-end系の扱いはどうする？今後の主流になっていくと思われる。デザインに抜けはないか？
- 大規模データの扱い
- データセットの抽象化をもっとちゃんとしないと

Background
----------

-  統計的音声合成（以下、音声合成）、統計的声質変換（以下、声質変換）はテキスト分析、音声分析/合成、機械学習等、いくらかの要素技術からなる複合技術であり、論文の追試（結果の再現）、新しいアイデアをプロトタイピングするといった行為は、大きな労力を要する。後の研究の生産性の向上のために、音声合成における要素技術を、再利用しやすい形で提供することには価値があると考える。
-  HHMM音声合成では、HTSが広く使われている。HTKにパッチを適用することで使用する。HMMベースの音響モデルを構築するための仕組みがコマンドラインツール群として提供されており、それらを組みわせて柔軟にシステムが作れるように設計されている。しかし、HMMベースの音声合成に着目して設計されているため、近年の主流であるDNN音声合成には基本的には対応していない。
-  `Merin <http://ssw9.net/papers/ssw9_PS2-13_Wu.pdf>`_ は、DNNベースの音声合成システムを作るためのツールキットである。近年のDNNベースの音声合成システムの成功を受けて、HTSに代わるDNNベースのstate-of-the-artなシステムを再現可能な形で提供するために作られている。音声認識のためのライブラリであるkaldiに習い、レシピという形で音声合成を行うためのスクリプト（HTSでのデモスクリプトにあたる）を提供している。Melinの主なエントリーポイントは、run_merlin.pyというコマンドラインスクリプトであり、ユーザは設定ファイルを切り替えることで、どのような音響モデルを使用するかなどを切り替える。しかし、run_merlin.pyがすべてのインタフェースとなっており、構成要素を再利用するといったことが難しい。また、音響モデルを設定ファイルで切り替えるという設計がゆえに、Merlinのソースコードを改変せずに音響モデルを自在に変えることも難しく、柔軟性に欠けている。

まとめると、音声合成における構成要素を対話的に試すことができ、HMM音声合成だけでなく、DNN音声合成、さらにはEnd-to-end音声合成も視野に入れたソフトウェアがあると望ましいと考える。

Goal
----

対話環境での試行錯誤が研究の生産性の向上に重要であると信じ、対話環境での利用を前提とした、音声合成、声質変換などの音声に特化した機械学習の共通基盤を構築することを目的とする。コードはMITライセンスで公開し、研究の再現性の保証にも役立つことも狙う。

音声合成においては、言語特徴量＋音響特徴量を入力としたDNN音声合成だけでなく、End-to-end音声合成の構成要素としても使用可能であることも目標とする。

So what do we provide?
----------------------

HMM音声合成からのDNN音声合成の発展、End-to-end音声合成、Wavenetのようなボコーダレスの音声合成の発展など、音声合成の枠組みは多岐に渡る。すべてを網羅する機能を提供することは困難であり、ライブラリを複雑かつメンテナンスを難しいものにしてしまう。したがって、提供する機能を最も汎用的な部分に留めることが重要であると考える。
また、扱うデータ量は大きくなっており、大規模データも視野に入れる必要がある。

DNNを用いた機械学習においては、tensorflow, keras, cntk, pytorch, theano,
caffe, mxnet,
chainer等に代表されるように、CUDAを活用した多次元配列（テンソル）上の数値演算、自動微分をサポートしたフレームワークが必須になってきている。音声、画像、言語など、データをテンソルとして表現できる場合は多くあり、ドメインを問わず多くの分野で使われている。
本ライブラリは、そういった汎用的な自動微分フレームワークと併せて使用されることを想定し、

-  言語特徴量、音響特徴量に対するテンソル表現、大規模データを視野にいれたデータアクセスの抽象化
-  音声に特化した自動微分をサポートした関数（autograd functions）
-  最低限の前処理アルゴリズム

に主に注目し、機能を提供すればよいと考える。また、可視化が重要であるという信念のもと、言語特徴量、音響特徴量の可視化ツールも提供する。

Design decisions
----------------

ソフトウェアの設計方針として、以下が挙げられる。

1. 対話環境で使えるPythonパッケージとして提供する。コマンドラインツールは、必要であればユーザが作ればよいと考え、本ライブラリでは提供しないこととする。
2. 対話環境での使用を前提とするため、基本的にIOはin-memoryととる。ファイルIOをAPIには使用しない
3. 音響モデルの提供は、ライブラリの範囲外とする。もっともユーザが自分で考えて設定したい部分と考えられるためである。Merlinとは異なり、音響モデルを提供するのではなく、音響モデルを構築するための要素を提供する。
4. 言語特徴量の抽出 (i.e. frontend)
   は、基本的にHTSやMerlinと同様にライブラリの範囲外とする。
5. 音響特徴量の抽出は、ライブラリの範囲外とする。 ``pysptk``,
   ``pyworld``, ``librosa`` など別パッケージを使用すればよい。

HTSのデモスクリプトのように、音声合成システム全体が複雑になってしまうのは、避けられない問題であると考える。本ライブラリでは、構成要素がシンプルで小さく、要素同士が疎結合であることを目指し、理解しやすい、再利用しやすいソフトウェアを目指す。

Development guidelines
----------------------

開発においては、以下を指針とする

-  **Respect other frameworks**: 車輪の再発明は可能な限り避ける
-  **Fully unit tested**:
   バグのないソフトウェアはない。テストによって、可能な限りバグを少なくする、再発を避ける。
-  **Documentation**: ドキュメントを書くのは大変だが、大事である
- Zen of python

Summary
-------

WIP: Data abstractions, preprocessing and autograd functions for machine
learning on speech designed for interactive prototyping.

-  **Designed for interactive prototyping**
-  **Modular design**: 疎結合な設計、APIとしての利用前提
-  **Tensor & autograd friendly**:
   最小限の労力で、自動微分フレームワークと併せて使用可能

.. [1]
   DNN音声合成を行うデモスクリプトは存在するが、あくまでデモスクリプトであり、ライブラリとしての機能にあるわけではない。
